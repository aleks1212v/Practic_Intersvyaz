{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Word2Vec_training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"JJFi9mwZwTxc","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e96db8b5-26bc-40f7-fbf4-591c6d7f0692"},"source":["#WORD2VEC model\n","\n","import logging\n","import pymysql\n","import multiprocessing\n","import gensim\n","from gensim.models import Word2Vec\n","\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","from multiprocessing import cpu_count\n","cpu_count = cpu_count()\n","print(f\"Количество потоков: {cpu_count}\")\n","\n","import numpy as np\n","\n","# Connect to the database\n","def get_connection():\n","    connection = pymysql.connect(host='database-3.chim8btj05zt.us-east-1.rds.amazonaws.com',\n","                                 user='admin',\n","                                 password='01035007',\n","                                 db='test1',\n","                                 charset='utf8mb4',\n","                                 cursorclass=pymysql.cursors.DictCursor)\n","    return connection\n","\n","# Create the tagged document needed for Doc2Vec\n","#def create_tagged_document(list_of_list_of_words):\n","#    for i, list_of_words in enumerate(list_of_list_of_words):\n","#        yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n","\n","\n","connection = get_connection()\n","\n","EPOCHS_0 = 100 #эпохи первичное обучение\n","EPOCHS_1 = 50 #эпохи дообучение\n","COUNT_DB = 10314497 #число строк в обработанной БД\n","LIMIT_0 = 1000000 #загружаем столько строк для первичного обучения модели\n","LIMIT_1 = LIMIT_0 // 2  #загружаем столько строк для последующего обучения модели\n","\n","SIZE = 500 #размерность выходного вектора признаков\n","ITER = 0 #C какой итерации дообучать (0 - первичное обучение)\n","\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n","try:\n","    with connection.cursor() as cursor:\n","        if ITER == 0:\n","            \n","            #загрузка данных для iter_0\n","            s = \"SELECT ttext_stem FROM sentiment_v3 ORDER BY id ASC LIMIT %s\"\n","            cursor.execute(s, (LIMIT_0))\n","            result = cursor.fetchall()\n","            result = [doc['ttext_stem'].split('|') for doc in result]\n","            print(f\"Считано {len(result)} строк из базы данных\")\n","\n","            #вычисление конечного id для ITER_0\n","            s = \"SELECT max(id) FROM (SELECT id from sentiment_v3 ORDER BY id ASC LIMIT %s) AS t\"\n","            cursor.execute(s, (LIMIT_0))\n","            end_id = cursor.fetchone()['max(id)']\n","            print(end_id)\n","\n","            #вычисление максимального id для всей БД\n","            s = \"SELECT max(id) FROM sentiment_v3\"\n","            cursor.execute(s)\n","            max_id = cursor.fetchone()['max(id)']\n","\n","            train_data = result\n","\n","            #instantiate our DM and DBOW models\n","            model = Word2Vec(min_count=3, window=5,  size=SIZE, sample=1e-3, negative=5, workers=cpu_count)\n","            \n","            #build vocab over all reviews\n","            model.build_vocab(train_data, update = False)\n","\n","            #train\n","            model.train(sentences=train_data, epochs=EPOCHS_0, total_examples=model.corpus_count)\n","            model.save(\"/gdrive/My Drive/Colab Notebooks/model500_iter_0.word2vec\", sep_limit = 100 * 1024 ** 2)\n","            #model.delete_temporary_training_data()\n","          \n","            print(f\"Модель model_dm записана на гугл диск\")\n","            COUNT_DB -= LIMIT_0\n","            print(f\"Осталось обработать {COUNT_DB} записей!\")\n","            ITER += 1\n","\n","        else:\n","            #вычисление конечного id для ITER_X\n","            s = \"SELECT max(id) FROM (SELECT id from sentiment_v3 ORDER BY id ASC LIMIT %s) AS t\"\n","            cursor.execute(s, (LIMIT_0 + LIMIT_1 * (ITER - 1)))\n","            end_id = cursor.fetchone()['max(id)']\n","            print(end_id)\n","\n","            #вычисление максимального id для всей БД\n","            s = \"SELECT max(id) FROM sentiment_v3\"\n","            cursor.execute(s)\n","            max_id = cursor.fetchone()['max(id)']\n","\n","        \n","        # дообучение\n","        while end_id < max_id:\n","            \n","            print(f\"Итерация {ITER}:\")\n","            model_old_pach = \"/gdrive/My Drive/Colab Notebooks/model500_iter_\" + str(ITER - 1) + \".word2vec\"\n","            model_pach = \"/gdrive/My Drive/Colab Notebooks/model500_iter_\" + str(ITER) + \".word2vec\"\n","\n","\n","            #загрузка данных для iter_X\n","            s = \"SELECT ttext_stem FROM sentiment_v3 WHERE id > %s ORDER BY id ASC LIMIT %s\"\n","            cursor.execute(s, (end_id, LIMIT_1))\n","            result = cursor.fetchall()\n","            result = [doc['ttext_stem'].split('|') for doc in result]\n","            print(f\"Считано {len(result)} строк из базы данных\")\n","\n","            #вычисление конечного id для ITER_X\n","            s = \"SELECT max(id) FROM (SELECT id FROM sentiment_v3 WHERE id > %s ORDER BY id ASC LIMIT %s) AS t\"\n","            cursor.execute(s, (end_id, LIMIT_1))\n","            end_id = cursor.fetchone()['max(id)']\n","\n","            train_data = result\n","\n","            #instantiate our models\n","\n","            model = Word2Vec.load(model_old_pach) #, mmap='r')  \n","            \n","            #build vocab over all reviews\n","            model.build_vocab(train_data, update = True)\n","            \n","            #train\n","            model.train(sentences=train_data, epochs=EPOCHS_1, total_examples=model.corpus_count)\n","\n","            #model.delete_temporary_training_data()\n","\n","            model.save(model_pach, sep_limit = 100 * 1024 ** 2)\n","            print(f\"Модель записана на гугл диск\")\n","\n","            COUNT_DB -= LIMIT_1\n","            print(f\"Осталось обработать {COUNT_DB} записей!\")\n","\n","            ITER += 1\n","finally:\n","    connection.close()\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","Количество потоков: 2\n","Считано 1000000 строк из базы данных\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-19 14:50:42,323 : INFO : collecting all words and their counts\n","2020-07-19 14:50:42,325 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n","2020-07-19 14:50:42,359 : INFO : PROGRESS: at sentence #10000, processed 93642 words, keeping 20543 word types\n","2020-07-19 14:50:42,388 : INFO : PROGRESS: at sentence #20000, processed 185663 words, keeping 33005 word types\n","2020-07-19 14:50:42,421 : INFO : PROGRESS: at sentence #30000, processed 276092 words, keeping 43525 word types\n","2020-07-19 14:50:42,451 : INFO : PROGRESS: at sentence #40000, processed 366878 words, keeping 53121 word types\n"],"name":"stderr"},{"output_type":"stream","text":["409921322009915392\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-19 14:50:42,483 : INFO : PROGRESS: at sentence #50000, processed 458016 words, keeping 62001 word types\n","2020-07-19 14:50:42,515 : INFO : PROGRESS: at sentence #60000, processed 547541 words, keeping 70359 word types\n","2020-07-19 14:50:42,543 : INFO : PROGRESS: at sentence #70000, processed 628467 words, keeping 77131 word types\n","2020-07-19 14:50:42,572 : INFO : PROGRESS: at sentence #80000, processed 708605 words, keeping 83497 word types\n","2020-07-19 14:50:42,600 : INFO : PROGRESS: at sentence #90000, processed 789806 words, keeping 89787 word types\n","2020-07-19 14:50:42,632 : INFO : PROGRESS: at sentence #100000, processed 872362 words, keeping 96005 word types\n","2020-07-19 14:50:42,667 : INFO : PROGRESS: at sentence #110000, processed 955009 words, keeping 102155 word types\n","2020-07-19 14:50:42,697 : INFO : PROGRESS: at sentence #120000, processed 1039528 words, keeping 108432 word types\n","2020-07-19 14:50:42,726 : INFO : PROGRESS: at sentence #130000, processed 1126957 words, keeping 115033 word types\n","2020-07-19 14:50:42,759 : INFO : PROGRESS: at sentence #140000, processed 1216132 words, keeping 121510 word types\n","2020-07-19 14:50:42,790 : INFO : PROGRESS: at sentence #150000, processed 1307976 words, keeping 127917 word types\n","2020-07-19 14:50:42,824 : INFO : PROGRESS: at sentence #160000, processed 1401973 words, keeping 134513 word types\n","2020-07-19 14:50:42,858 : INFO : PROGRESS: at sentence #170000, processed 1498164 words, keeping 140978 word types\n","2020-07-19 14:50:42,894 : INFO : PROGRESS: at sentence #180000, processed 1593279 words, keeping 147301 word types\n","2020-07-19 14:50:42,933 : INFO : PROGRESS: at sentence #190000, processed 1684805 words, keeping 153601 word types\n","2020-07-19 14:50:42,965 : INFO : PROGRESS: at sentence #200000, processed 1771787 words, keeping 159404 word types\n","2020-07-19 14:50:42,995 : INFO : PROGRESS: at sentence #210000, processed 1860758 words, keeping 165215 word types\n","2020-07-19 14:50:43,030 : INFO : PROGRESS: at sentence #220000, processed 1950042 words, keeping 171039 word types\n","2020-07-19 14:50:43,068 : INFO : PROGRESS: at sentence #230000, processed 2037812 words, keeping 177209 word types\n","2020-07-19 14:50:43,099 : INFO : PROGRESS: at sentence #240000, processed 2126765 words, keeping 183510 word types\n","2020-07-19 14:50:43,130 : INFO : PROGRESS: at sentence #250000, processed 2215407 words, keeping 189774 word types\n","2020-07-19 14:50:43,163 : INFO : PROGRESS: at sentence #260000, processed 2303371 words, keeping 195524 word types\n","2020-07-19 14:50:43,193 : INFO : PROGRESS: at sentence #270000, processed 2393054 words, keeping 201563 word types\n","2020-07-19 14:50:43,229 : INFO : PROGRESS: at sentence #280000, processed 2483760 words, keeping 207852 word types\n","2020-07-19 14:50:43,261 : INFO : PROGRESS: at sentence #290000, processed 2575646 words, keeping 214375 word types\n","2020-07-19 14:50:43,298 : INFO : PROGRESS: at sentence #300000, processed 2665558 words, keeping 220421 word types\n","2020-07-19 14:50:43,328 : INFO : PROGRESS: at sentence #310000, processed 2752603 words, keeping 225678 word types\n","2020-07-19 14:50:43,362 : INFO : PROGRESS: at sentence #320000, processed 2839875 words, keeping 230935 word types\n","2020-07-19 14:50:43,394 : INFO : PROGRESS: at sentence #330000, processed 2925942 words, keeping 236066 word types\n","2020-07-19 14:50:43,432 : INFO : PROGRESS: at sentence #340000, processed 3013542 words, keeping 241449 word types\n","2020-07-19 14:50:43,462 : INFO : PROGRESS: at sentence #350000, processed 3099168 words, keeping 246252 word types\n","2020-07-19 14:50:43,494 : INFO : PROGRESS: at sentence #360000, processed 3184099 words, keeping 251086 word types\n","2020-07-19 14:50:43,526 : INFO : PROGRESS: at sentence #370000, processed 3267850 words, keeping 255667 word types\n","2020-07-19 14:50:43,559 : INFO : PROGRESS: at sentence #380000, processed 3352295 words, keeping 260233 word types\n","2020-07-19 14:50:43,588 : INFO : PROGRESS: at sentence #390000, processed 3436382 words, keeping 264832 word types\n","2020-07-19 14:50:43,620 : INFO : PROGRESS: at sentence #400000, processed 3521568 words, keeping 269265 word types\n","2020-07-19 14:50:43,651 : INFO : PROGRESS: at sentence #410000, processed 3606937 words, keeping 273676 word types\n","2020-07-19 14:50:43,688 : INFO : PROGRESS: at sentence #420000, processed 3692594 words, keeping 278179 word types\n","2020-07-19 14:50:43,722 : INFO : PROGRESS: at sentence #430000, processed 3777360 words, keeping 282569 word types\n","2020-07-19 14:50:43,754 : INFO : PROGRESS: at sentence #440000, processed 3861132 words, keeping 287037 word types\n","2020-07-19 14:50:43,786 : INFO : PROGRESS: at sentence #450000, processed 3945348 words, keeping 291208 word types\n","2020-07-19 14:50:43,815 : INFO : PROGRESS: at sentence #460000, processed 4030492 words, keeping 295279 word types\n","2020-07-19 14:50:43,847 : INFO : PROGRESS: at sentence #470000, processed 4115829 words, keeping 299607 word types\n","2020-07-19 14:50:43,881 : INFO : PROGRESS: at sentence #480000, processed 4203677 words, keeping 304278 word types\n","2020-07-19 14:50:43,916 : INFO : PROGRESS: at sentence #490000, processed 4289907 words, keeping 308692 word types\n","2020-07-19 14:50:43,947 : INFO : PROGRESS: at sentence #500000, processed 4376129 words, keeping 312929 word types\n","2020-07-19 14:50:43,976 : INFO : PROGRESS: at sentence #510000, processed 4463555 words, keeping 317329 word types\n","2020-07-19 14:50:44,018 : INFO : PROGRESS: at sentence #520000, processed 4567748 words, keeping 324011 word types\n","2020-07-19 14:50:44,057 : INFO : PROGRESS: at sentence #530000, processed 4676808 words, keeping 331313 word types\n","2020-07-19 14:50:44,097 : INFO : PROGRESS: at sentence #540000, processed 4788151 words, keeping 338618 word types\n","2020-07-19 14:50:44,140 : INFO : PROGRESS: at sentence #550000, processed 4902670 words, keeping 346471 word types\n","2020-07-19 14:50:44,201 : INFO : PROGRESS: at sentence #560000, processed 5021481 words, keeping 355477 word types\n","2020-07-19 14:50:44,242 : INFO : PROGRESS: at sentence #570000, processed 5133645 words, keeping 362789 word types\n","2020-07-19 14:50:44,283 : INFO : PROGRESS: at sentence #580000, processed 5245906 words, keeping 370245 word types\n","2020-07-19 14:50:44,325 : INFO : PROGRESS: at sentence #590000, processed 5348947 words, keeping 376153 word types\n","2020-07-19 14:50:44,366 : INFO : PROGRESS: at sentence #600000, processed 5450466 words, keeping 381908 word types\n","2020-07-19 14:50:44,404 : INFO : PROGRESS: at sentence #610000, processed 5552368 words, keeping 388131 word types\n","2020-07-19 14:50:44,438 : INFO : PROGRESS: at sentence #620000, processed 5643312 words, keeping 392965 word types\n","2020-07-19 14:50:44,470 : INFO : PROGRESS: at sentence #630000, processed 5733456 words, keeping 397428 word types\n","2020-07-19 14:50:44,506 : INFO : PROGRESS: at sentence #640000, processed 5826450 words, keeping 402446 word types\n","2020-07-19 14:50:44,540 : INFO : PROGRESS: at sentence #650000, processed 5919439 words, keeping 407315 word types\n","2020-07-19 14:50:44,570 : INFO : PROGRESS: at sentence #660000, processed 6008031 words, keeping 411106 word types\n","2020-07-19 14:50:44,603 : INFO : PROGRESS: at sentence #670000, processed 6097270 words, keeping 415054 word types\n","2020-07-19 14:50:44,638 : INFO : PROGRESS: at sentence #680000, processed 6186294 words, keeping 419189 word types\n","2020-07-19 14:50:44,676 : INFO : PROGRESS: at sentence #690000, processed 6277281 words, keeping 424001 word types\n","2020-07-19 14:50:44,709 : INFO : PROGRESS: at sentence #700000, processed 6367645 words, keeping 428364 word types\n","2020-07-19 14:50:44,740 : INFO : PROGRESS: at sentence #710000, processed 6453503 words, keeping 432675 word types\n","2020-07-19 14:50:44,776 : INFO : PROGRESS: at sentence #720000, processed 6543922 words, keeping 437451 word types\n","2020-07-19 14:50:44,812 : INFO : PROGRESS: at sentence #730000, processed 6635019 words, keeping 442400 word types\n","2020-07-19 14:50:44,842 : INFO : PROGRESS: at sentence #740000, processed 6720170 words, keeping 446443 word types\n","2020-07-19 14:50:44,877 : INFO : PROGRESS: at sentence #750000, processed 6811712 words, keeping 450578 word types\n","2020-07-19 14:50:44,912 : INFO : PROGRESS: at sentence #760000, processed 6905033 words, keeping 454923 word types\n","2020-07-19 14:50:44,945 : INFO : PROGRESS: at sentence #770000, processed 6996792 words, keeping 459139 word types\n","2020-07-19 14:50:44,976 : INFO : PROGRESS: at sentence #780000, processed 7087496 words, keeping 463467 word types\n","2020-07-19 14:50:45,007 : INFO : PROGRESS: at sentence #790000, processed 7166578 words, keeping 467441 word types\n","2020-07-19 14:50:45,041 : INFO : PROGRESS: at sentence #800000, processed 7243811 words, keeping 470940 word types\n","2020-07-19 14:50:45,069 : INFO : PROGRESS: at sentence #810000, processed 7321531 words, keeping 474589 word types\n","2020-07-19 14:50:45,101 : INFO : PROGRESS: at sentence #820000, processed 7398925 words, keeping 478242 word types\n","2020-07-19 14:50:45,131 : INFO : PROGRESS: at sentence #830000, processed 7474989 words, keeping 481653 word types\n","2020-07-19 14:50:45,159 : INFO : PROGRESS: at sentence #840000, processed 7550901 words, keeping 485044 word types\n","2020-07-19 14:50:45,192 : INFO : PROGRESS: at sentence #850000, processed 7628004 words, keeping 488581 word types\n","2020-07-19 14:50:45,226 : INFO : PROGRESS: at sentence #860000, processed 7704257 words, keeping 492006 word types\n","2020-07-19 14:50:45,261 : INFO : PROGRESS: at sentence #870000, processed 7791628 words, keeping 496447 word types\n","2020-07-19 14:50:45,295 : INFO : PROGRESS: at sentence #880000, processed 7883683 words, keeping 501304 word types\n","2020-07-19 14:50:45,330 : INFO : PROGRESS: at sentence #890000, processed 7973617 words, keeping 506004 word types\n","2020-07-19 14:50:45,364 : INFO : PROGRESS: at sentence #900000, processed 8063180 words, keeping 510916 word types\n","2020-07-19 14:50:45,398 : INFO : PROGRESS: at sentence #910000, processed 8153238 words, keeping 515651 word types\n","2020-07-19 14:50:45,432 : INFO : PROGRESS: at sentence #920000, processed 8241881 words, keeping 520244 word types\n","2020-07-19 14:50:45,468 : INFO : PROGRESS: at sentence #930000, processed 8330627 words, keeping 524941 word types\n","2020-07-19 14:50:45,503 : INFO : PROGRESS: at sentence #940000, processed 8415720 words, keeping 528936 word types\n","2020-07-19 14:50:45,538 : INFO : PROGRESS: at sentence #950000, processed 8497530 words, keeping 532745 word types\n","2020-07-19 14:50:45,568 : INFO : PROGRESS: at sentence #960000, processed 8577843 words, keeping 536376 word types\n","2020-07-19 14:50:45,602 : INFO : PROGRESS: at sentence #970000, processed 8661297 words, keeping 540251 word types\n","2020-07-19 14:50:45,637 : INFO : PROGRESS: at sentence #980000, processed 8747693 words, keeping 544470 word types\n","2020-07-19 14:50:45,672 : INFO : PROGRESS: at sentence #990000, processed 8837213 words, keeping 549005 word types\n","2020-07-19 14:50:45,713 : INFO : collected 553433 word types from a corpus of 8925140 raw words and 1000000 sentences\n","2020-07-19 14:50:45,714 : INFO : Loading a fresh vocabulary\n","2020-07-19 14:50:46,364 : INFO : effective_min_count=3 retains 93359 unique words (16% of original 553433, drops 460074)\n","2020-07-19 14:50:46,365 : INFO : effective_min_count=3 leaves 8340866 word corpus (93% of original 8925140, drops 584274)\n","2020-07-19 14:50:46,684 : INFO : deleting the raw counts dictionary of 553433 items\n","2020-07-19 14:50:46,700 : INFO : sample=0.001 downsamples 19 most-common words\n","2020-07-19 14:50:46,701 : INFO : downsampling leaves estimated 6216094 word corpus (74.5% of prior 8340866)\n","2020-07-19 14:50:47,066 : INFO : estimated required memory for 93359 words and 500 dimensions: 420115500 bytes\n","2020-07-19 14:50:47,067 : INFO : resetting layer weights\n","2020-07-19 14:51:06,016 : INFO : training model with 2 workers on 93359 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n","2020-07-19 14:51:07,059 : INFO : EPOCH 1 - PROGRESS: at 4.03% examples, 247420 words/s, in_qsize 3, out_qsize 0\n","2020-07-19 14:51:08,076 : INFO : EPOCH 1 - PROGRESS: at 8.26% examples, 249372 words/s, in_qsize 4, out_qsize 1\n","2020-07-19 14:51:09,086 : INFO : EPOCH 1 - PROGRESS: at 12.34% examples, 248384 words/s, in_qsize 2, out_qsize 1\n","2020-07-19 14:51:10,128 : INFO : EPOCH 1 - PROGRESS: at 16.29% examples, 248110 words/s, in_qsize 3, out_qsize 0\n","2020-07-19 14:51:11,139 : INFO : EPOCH 1 - PROGRESS: at 20.19% examples, 248263 words/s, in_qsize 3, out_qsize 0\n","2020-07-19 14:51:12,153 : INFO : EPOCH 1 - PROGRESS: at 24.25% examples, 247273 words/s, in_qsize 2, out_qsize 1\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GMla2Y4N526k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e83e6006-bc8f-4611-d903-b1ac1a5deaff"},"source":["#Обновление модели doc2vec\n","import logging\n","import pymysql\n","import multiprocessing\n","import gensim\n","from gensim.models import Doc2Vec\n","\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","from multiprocessing import cpu_count\n","cpu_count = cpu_count()\n","print(f\"Количество потоков: {cpu_count}\")\n","\n","import numpy as np\n","\n","# Connect to the database\n","def get_connection():\n","    connection = pymysql.connect(host='database-3.chim8btj05zt.us-east-1.rds.amazonaws.com',\n","                                 user='admin',\n","                                 password='01035007',\n","                                 db='test1',\n","                                 charset='utf8mb4',\n","                                 cursorclass=pymysql.cursors.DictCursor)\n","    return connection\n","\n","# Create the tagged document needed for Doc2Vec\n","def create_tagged_document(list_of_list_of_words):\n","    for i, list_of_words in enumerate(list_of_list_of_words):\n","        yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n","\n","\n","connection = get_connection()\n","\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n","try:\n","    with connection.cursor() as cursor:\n","\n","        \n","  \n","\n","finally:\n","    connection.close()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","Количество потоков: 2\n","Считано 1699863 строк из базы данных\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-18 08:44:32,055 : INFO : loading Doc2Vec object from /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec\n","/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n","2020-07-18 08:44:32,610 : INFO : loading vocabulary recursively from /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec.vocabulary.* with mmap=None\n","2020-07-18 08:44:32,611 : INFO : loading trainables recursively from /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec.trainables.* with mmap=None\n","2020-07-18 08:44:32,613 : INFO : loading syn1neg from /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec.trainables.syn1neg.npy with mmap=None\n","2020-07-18 08:44:41,662 : INFO : loading wv recursively from /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec.wv.* with mmap=None\n","2020-07-18 08:44:41,663 : INFO : loading vectors from /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec.wv.vectors.npy with mmap=None\n","2020-07-18 08:44:50,663 : INFO : loading docvecs recursively from /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec.docvecs.* with mmap=None\n","2020-07-18 08:44:50,664 : INFO : loading vectors_docs from /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec.docvecs.vectors_docs.npy with mmap=None\n","2020-07-18 08:45:37,947 : INFO : loaded /gdrive/My Drive/Colab Notebooks/model_dm.doc2vec\n","2020-07-18 08:45:38,712 : INFO : collecting all words and their counts\n","2020-07-18 08:45:38,713 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 1298527 tags\n","2020-07-18 08:45:38,761 : INFO : PROGRESS: at example #10000, processed 77849 words (1637947/s), 18218 word types, 1298527 tags\n","2020-07-18 08:45:38,804 : INFO : PROGRESS: at example #20000, processed 156319 words (1893312/s), 28673 word types, 1298527 tags\n","2020-07-18 08:45:38,845 : INFO : PROGRESS: at example #30000, processed 235560 words (1944480/s), 37916 word types, 1298527 tags\n","2020-07-18 08:45:38,891 : INFO : PROGRESS: at example #40000, processed 313735 words (1726026/s), 46205 word types, 1298527 tags\n","2020-07-18 08:45:38,932 : INFO : PROGRESS: at example #50000, processed 393915 words (2053979/s), 53929 word types, 1298527 tags\n","2020-07-18 08:45:38,975 : INFO : PROGRESS: at example #60000, processed 475678 words (1936868/s), 61916 word types, 1298527 tags\n","2020-07-18 08:45:39,021 : INFO : PROGRESS: at example #70000, processed 562228 words (1932753/s), 70669 word types, 1298527 tags\n","2020-07-18 08:45:39,069 : INFO : PROGRESS: at example #80000, processed 653789 words (1934429/s), 80033 word types, 1298527 tags\n","2020-07-18 08:45:39,122 : INFO : PROGRESS: at example #90000, processed 745936 words (1801389/s), 89091 word types, 1298527 tags\n","2020-07-18 08:45:39,176 : INFO : PROGRESS: at example #100000, processed 837430 words (1811617/s), 97756 word types, 1298527 tags\n","2020-07-18 08:45:39,225 : INFO : PROGRESS: at example #110000, processed 930045 words (1927560/s), 105840 word types, 1298527 tags\n","2020-07-18 08:45:39,275 : INFO : PROGRESS: at example #120000, processed 1023451 words (1897806/s), 113740 word types, 1298527 tags\n","2020-07-18 08:45:39,324 : INFO : PROGRESS: at example #130000, processed 1118053 words (1971960/s), 121737 word types, 1298527 tags\n","2020-07-18 08:45:39,372 : INFO : PROGRESS: at example #140000, processed 1206725 words (1894330/s), 128822 word types, 1298527 tags\n","2020-07-18 08:45:39,420 : INFO : PROGRESS: at example #150000, processed 1293947 words (1863588/s), 135475 word types, 1298527 tags\n","2020-07-18 08:45:39,469 : INFO : PROGRESS: at example #160000, processed 1382241 words (1897296/s), 142514 word types, 1298527 tags\n","2020-07-18 08:45:39,517 : INFO : PROGRESS: at example #170000, processed 1469710 words (1888847/s), 148967 word types, 1298527 tags\n","2020-07-18 08:45:39,564 : INFO : PROGRESS: at example #180000, processed 1554598 words (1844253/s), 154802 word types, 1298527 tags\n","2020-07-18 08:45:39,612 : INFO : PROGRESS: at example #190000, processed 1637785 words (1772326/s), 160506 word types, 1298527 tags\n","2020-07-18 08:45:39,656 : INFO : PROGRESS: at example #200000, processed 1720795 words (1907990/s), 165909 word types, 1298527 tags\n","2020-07-18 08:45:39,703 : INFO : PROGRESS: at example #210000, processed 1803170 words (1820780/s), 171201 word types, 1298527 tags\n","2020-07-18 08:45:39,758 : INFO : PROGRESS: at example #220000, processed 1884523 words (1496015/s), 176315 word types, 1298527 tags\n","2020-07-18 08:45:39,805 : INFO : PROGRESS: at example #230000, processed 1967666 words (1826051/s), 181436 word types, 1298527 tags\n","2020-07-18 08:45:39,851 : INFO : PROGRESS: at example #240000, processed 2050182 words (1826089/s), 186374 word types, 1298527 tags\n","2020-07-18 08:45:39,896 : INFO : PROGRESS: at example #250000, processed 2131846 words (1846916/s), 191391 word types, 1298527 tags\n","2020-07-18 08:45:39,938 : INFO : PROGRESS: at example #260000, processed 2206631 words (1831159/s), 195628 word types, 1298527 tags\n","2020-07-18 08:45:39,978 : INFO : PROGRESS: at example #270000, processed 2280189 words (1884535/s), 199575 word types, 1298527 tags\n","2020-07-18 08:45:40,021 : INFO : PROGRESS: at example #280000, processed 2352810 words (1729372/s), 203416 word types, 1298527 tags\n","2020-07-18 08:45:40,065 : INFO : PROGRESS: at example #290000, processed 2427520 words (1769139/s), 207426 word types, 1298527 tags\n","2020-07-18 08:45:40,107 : INFO : PROGRESS: at example #300000, processed 2503410 words (1818845/s), 211442 word types, 1298527 tags\n","2020-07-18 08:45:40,154 : INFO : PROGRESS: at example #310000, processed 2581555 words (1691065/s), 215683 word types, 1298527 tags\n","2020-07-18 08:45:40,199 : INFO : PROGRESS: at example #320000, processed 2664517 words (1885662/s), 220459 word types, 1298527 tags\n","2020-07-18 08:45:40,248 : INFO : PROGRESS: at example #330000, processed 2754630 words (1885132/s), 226305 word types, 1298527 tags\n","2020-07-18 08:45:40,297 : INFO : PROGRESS: at example #340000, processed 2845498 words (1914545/s), 232005 word types, 1298527 tags\n","2020-07-18 08:45:40,346 : INFO : PROGRESS: at example #350000, processed 2937837 words (1918353/s), 237744 word types, 1298527 tags\n","2020-07-18 08:45:40,395 : INFO : PROGRESS: at example #360000, processed 3029736 words (1909325/s), 243422 word types, 1298527 tags\n","2020-07-18 08:45:40,445 : INFO : PROGRESS: at example #370000, processed 3121539 words (1841827/s), 249156 word types, 1298527 tags\n","2020-07-18 08:45:40,493 : INFO : PROGRESS: at example #380000, processed 3213145 words (1969902/s), 254626 word types, 1298527 tags\n","2020-07-18 08:45:40,544 : INFO : PROGRESS: at example #390000, processed 3302252 words (1753345/s), 259812 word types, 1298527 tags\n","2020-07-18 08:45:40,595 : INFO : PROGRESS: at example #400000, processed 3392346 words (1825365/s), 264967 word types, 1298527 tags\n","2020-07-18 08:45:40,643 : INFO : PROGRESS: at example #410000, processed 3481073 words (1852719/s), 270098 word types, 1298527 tags\n","2020-07-18 08:45:40,695 : INFO : PROGRESS: at example #420000, processed 3571173 words (1782286/s), 275417 word types, 1298527 tags\n","2020-07-18 08:45:40,745 : INFO : PROGRESS: at example #430000, processed 3658632 words (1800770/s), 280408 word types, 1298527 tags\n","2020-07-18 08:45:40,797 : INFO : PROGRESS: at example #440000, processed 3746860 words (1717495/s), 285398 word types, 1298527 tags\n","2020-07-18 08:45:40,850 : INFO : PROGRESS: at example #450000, processed 3834802 words (1680197/s), 290378 word types, 1298527 tags\n","2020-07-18 08:45:40,896 : INFO : PROGRESS: at example #460000, processed 3922563 words (1985301/s), 295265 word types, 1298527 tags\n","2020-07-18 08:45:40,941 : INFO : PROGRESS: at example #470000, processed 4010047 words (1963185/s), 300162 word types, 1298527 tags\n","2020-07-18 08:45:40,988 : INFO : PROGRESS: at example #480000, processed 4098869 words (1915652/s), 305095 word types, 1298527 tags\n","2020-07-18 08:45:41,037 : INFO : PROGRESS: at example #490000, processed 4186812 words (1854790/s), 309849 word types, 1298527 tags\n","2020-07-18 08:45:41,083 : INFO : PROGRESS: at example #500000, processed 4271601 words (1866492/s), 314416 word types, 1298527 tags\n","2020-07-18 08:45:41,128 : INFO : PROGRESS: at example #510000, processed 4358636 words (1987608/s), 318981 word types, 1298527 tags\n","2020-07-18 08:45:41,176 : INFO : PROGRESS: at example #520000, processed 4446952 words (1855924/s), 323421 word types, 1298527 tags\n","2020-07-18 08:45:41,225 : INFO : PROGRESS: at example #530000, processed 4533552 words (1824825/s), 327712 word types, 1298527 tags\n","2020-07-18 08:45:41,272 : INFO : PROGRESS: at example #540000, processed 4620649 words (1869259/s), 332100 word types, 1298527 tags\n","2020-07-18 08:45:41,317 : INFO : PROGRESS: at example #550000, processed 4707241 words (1970782/s), 336460 word types, 1298527 tags\n","2020-07-18 08:45:41,365 : INFO : PROGRESS: at example #560000, processed 4794311 words (1852984/s), 340839 word types, 1298527 tags\n","2020-07-18 08:45:41,412 : INFO : PROGRESS: at example #570000, processed 4880565 words (1872160/s), 345099 word types, 1298527 tags\n","2020-07-18 08:45:41,460 : INFO : PROGRESS: at example #580000, processed 4966584 words (1859609/s), 349411 word types, 1298527 tags\n","2020-07-18 08:45:41,534 : INFO : PROGRESS: at example #590000, processed 5051689 words (1166561/s), 353576 word types, 1298527 tags\n","2020-07-18 08:45:41,580 : INFO : PROGRESS: at example #600000, processed 5136381 words (1856414/s), 357668 word types, 1298527 tags\n","2020-07-18 08:45:41,626 : INFO : PROGRESS: at example #610000, processed 5218390 words (1834488/s), 361526 word types, 1298527 tags\n","2020-07-18 08:45:41,670 : INFO : PROGRESS: at example #620000, processed 5298600 words (1843020/s), 365174 word types, 1298527 tags\n","2020-07-18 08:45:41,717 : INFO : PROGRESS: at example #630000, processed 5379474 words (1770148/s), 368833 word types, 1298527 tags\n","2020-07-18 08:45:41,763 : INFO : PROGRESS: at example #640000, processed 5459914 words (1761450/s), 372381 word types, 1298527 tags\n","2020-07-18 08:45:41,814 : INFO : PROGRESS: at example #650000, processed 5540518 words (1601702/s), 375942 word types, 1298527 tags\n","2020-07-18 08:45:41,863 : INFO : PROGRESS: at example #660000, processed 5619066 words (1661805/s), 379538 word types, 1298527 tags\n","2020-07-18 08:45:41,914 : INFO : PROGRESS: at example #670000, processed 5701662 words (1639648/s), 383361 word types, 1298527 tags\n","2020-07-18 08:45:41,959 : INFO : PROGRESS: at example #680000, processed 5783928 words (1880145/s), 387123 word types, 1298527 tags\n","2020-07-18 08:45:42,004 : INFO : PROGRESS: at example #690000, processed 5867435 words (1864072/s), 391006 word types, 1298527 tags\n","2020-07-18 08:45:42,051 : INFO : PROGRESS: at example #700000, processed 5952150 words (1860423/s), 395079 word types, 1298527 tags\n","2020-07-18 08:45:42,099 : INFO : PROGRESS: at example #710000, processed 6037941 words (1820583/s), 398983 word types, 1298527 tags\n","2020-07-18 08:45:42,148 : INFO : PROGRESS: at example #720000, processed 6125858 words (1828133/s), 403301 word types, 1298527 tags\n","2020-07-18 08:45:42,203 : INFO : PROGRESS: at example #730000, processed 6217231 words (1692112/s), 408238 word types, 1298527 tags\n","2020-07-18 08:45:42,254 : INFO : PROGRESS: at example #740000, processed 6302844 words (1705240/s), 412573 word types, 1298527 tags\n","2020-07-18 08:45:42,304 : INFO : PROGRESS: at example #750000, processed 6389704 words (1778955/s), 416959 word types, 1298527 tags\n","2020-07-18 08:45:42,354 : INFO : PROGRESS: at example #760000, processed 6479097 words (1817531/s), 421407 word types, 1298527 tags\n","2020-07-18 08:45:42,403 : INFO : PROGRESS: at example #770000, processed 6566306 words (1809637/s), 425714 word types, 1298527 tags\n","2020-07-18 08:45:42,458 : INFO : PROGRESS: at example #780000, processed 6655842 words (1677441/s), 430258 word types, 1298527 tags\n","2020-07-18 08:45:42,509 : INFO : PROGRESS: at example #790000, processed 6743162 words (1748090/s), 434595 word types, 1298527 tags\n","2020-07-18 08:45:42,563 : INFO : PROGRESS: at example #800000, processed 6834135 words (1722625/s), 439331 word types, 1298527 tags\n","2020-07-18 08:45:42,613 : INFO : PROGRESS: at example #810000, processed 6925065 words (1827267/s), 443776 word types, 1298527 tags\n","2020-07-18 08:45:42,663 : INFO : PROGRESS: at example #820000, processed 7014539 words (1839603/s), 448098 word types, 1298527 tags\n","2020-07-18 08:45:42,713 : INFO : PROGRESS: at example #830000, processed 7105100 words (1839475/s), 452559 word types, 1298527 tags\n","2020-07-18 08:45:42,767 : INFO : PROGRESS: at example #840000, processed 7198049 words (1769944/s), 457124 word types, 1298527 tags\n","2020-07-18 08:45:42,826 : INFO : PROGRESS: at example #850000, processed 7291619 words (1617755/s), 461915 word types, 1298527 tags\n","2020-07-18 08:45:42,876 : INFO : PROGRESS: at example #860000, processed 7385518 words (1889970/s), 466936 word types, 1298527 tags\n","2020-07-18 08:45:42,926 : INFO : PROGRESS: at example #870000, processed 7478105 words (1890219/s), 471805 word types, 1298527 tags\n","2020-07-18 08:45:42,976 : INFO : PROGRESS: at example #880000, processed 7568589 words (1836315/s), 476735 word types, 1298527 tags\n","2020-07-18 08:45:43,025 : INFO : PROGRESS: at example #890000, processed 7657669 words (1861660/s), 481544 word types, 1298527 tags\n","2020-07-18 08:45:43,077 : INFO : PROGRESS: at example #900000, processed 7744312 words (1712950/s), 486072 word types, 1298527 tags\n","2020-07-18 08:45:43,127 : INFO : PROGRESS: at example #910000, processed 7826664 words (1691777/s), 489954 word types, 1298527 tags\n","2020-07-18 08:45:43,175 : INFO : PROGRESS: at example #920000, processed 7910366 words (1769674/s), 493651 word types, 1298527 tags\n","2020-07-18 08:45:43,225 : INFO : PROGRESS: at example #930000, processed 7994750 words (1710031/s), 497394 word types, 1298527 tags\n","2020-07-18 08:45:43,272 : INFO : PROGRESS: at example #940000, processed 8076858 words (1787814/s), 501137 word types, 1298527 tags\n","2020-07-18 08:45:43,321 : INFO : PROGRESS: at example #950000, processed 8157846 words (1700639/s), 504654 word types, 1298527 tags\n","2020-07-18 08:45:43,368 : INFO : PROGRESS: at example #960000, processed 8239311 words (1777296/s), 508231 word types, 1298527 tags\n","2020-07-18 08:45:43,417 : INFO : PROGRESS: at example #970000, processed 8319559 words (1655956/s), 511755 word types, 1298527 tags\n","2020-07-18 08:45:43,464 : INFO : PROGRESS: at example #980000, processed 8398397 words (1739989/s), 515168 word types, 1298527 tags\n","2020-07-18 08:45:43,512 : INFO : PROGRESS: at example #990000, processed 8477340 words (1686285/s), 518496 word types, 1298527 tags\n","2020-07-18 08:45:43,567 : INFO : PROGRESS: at example #1000000, processed 8555650 words (1441421/s), 521884 word types, 1298527 tags\n","2020-07-18 08:45:43,614 : INFO : PROGRESS: at example #1010000, processed 8633438 words (1695870/s), 525082 word types, 1298527 tags\n","2020-07-18 08:45:43,661 : INFO : PROGRESS: at example #1020000, processed 8711753 words (1747121/s), 528340 word types, 1298527 tags\n","2020-07-18 08:45:43,708 : INFO : PROGRESS: at example #1030000, processed 8789184 words (1646554/s), 531495 word types, 1298527 tags\n","2020-07-18 08:45:43,755 : INFO : PROGRESS: at example #1040000, processed 8865892 words (1687521/s), 534590 word types, 1298527 tags\n","2020-07-18 08:45:43,799 : INFO : PROGRESS: at example #1050000, processed 8941728 words (1751833/s), 537900 word types, 1298527 tags\n","2020-07-18 08:45:43,853 : INFO : PROGRESS: at example #1060000, processed 9017311 words (1427947/s), 540965 word types, 1298527 tags\n","2020-07-18 08:45:43,898 : INFO : PROGRESS: at example #1070000, processed 9093028 words (1717031/s), 543947 word types, 1298527 tags\n","2020-07-18 08:45:43,943 : INFO : PROGRESS: at example #1080000, processed 9168662 words (1704497/s), 546821 word types, 1298527 tags\n","2020-07-18 08:45:43,991 : INFO : PROGRESS: at example #1090000, processed 9244117 words (1637667/s), 549626 word types, 1298527 tags\n","2020-07-18 08:45:44,038 : INFO : PROGRESS: at example #1100000, processed 9322288 words (1730610/s), 552649 word types, 1298527 tags\n","2020-07-18 08:45:44,088 : INFO : PROGRESS: at example #1110000, processed 9408416 words (1765166/s), 556637 word types, 1298527 tags\n","2020-07-18 08:45:44,139 : INFO : PROGRESS: at example #1120000, processed 9500404 words (1834091/s), 561681 word types, 1298527 tags\n","2020-07-18 08:45:44,190 : INFO : PROGRESS: at example #1130000, processed 9592611 words (1828503/s), 566467 word types, 1298527 tags\n","2020-07-18 08:45:44,245 : INFO : PROGRESS: at example #1140000, processed 9685507 words (1716734/s), 571513 word types, 1298527 tags\n","2020-07-18 08:45:44,297 : INFO : PROGRESS: at example #1150000, processed 9777181 words (1807657/s), 576227 word types, 1298527 tags\n","2020-07-18 08:45:44,349 : INFO : PROGRESS: at example #1160000, processed 9867058 words (1769941/s), 580843 word types, 1298527 tags\n","2020-07-18 08:45:44,402 : INFO : PROGRESS: at example #1170000, processed 9956632 words (1735760/s), 585328 word types, 1298527 tags\n","2020-07-18 08:45:44,451 : INFO : PROGRESS: at example #1180000, processed 10046291 words (1870171/s), 589727 word types, 1298527 tags\n","2020-07-18 08:45:44,502 : INFO : PROGRESS: at example #1190000, processed 10137136 words (1814967/s), 594045 word types, 1298527 tags\n","2020-07-18 08:45:44,556 : INFO : PROGRESS: at example #1200000, processed 10226655 words (1691422/s), 598199 word types, 1298527 tags\n","2020-07-18 08:45:44,607 : INFO : PROGRESS: at example #1210000, processed 10314849 words (1768145/s), 602195 word types, 1298527 tags\n","2020-07-18 08:45:44,657 : INFO : PROGRESS: at example #1220000, processed 10398736 words (1735338/s), 605710 word types, 1298527 tags\n","2020-07-18 08:45:44,707 : INFO : PROGRESS: at example #1230000, processed 10480119 words (1634149/s), 609048 word types, 1298527 tags\n","2020-07-18 08:45:44,756 : INFO : PROGRESS: at example #1240000, processed 10562037 words (1712786/s), 612536 word types, 1298527 tags\n","2020-07-18 08:45:44,804 : INFO : PROGRESS: at example #1250000, processed 10644645 words (1756063/s), 616147 word types, 1298527 tags\n","2020-07-18 08:45:44,857 : INFO : PROGRESS: at example #1260000, processed 10725684 words (1542550/s), 619877 word types, 1298527 tags\n","2020-07-18 08:45:44,905 : INFO : PROGRESS: at example #1270000, processed 10806672 words (1738453/s), 623331 word types, 1298527 tags\n","2020-07-18 08:45:44,952 : INFO : PROGRESS: at example #1280000, processed 10887263 words (1783083/s), 626575 word types, 1298527 tags\n","2020-07-18 08:45:44,999 : INFO : PROGRESS: at example #1290000, processed 10967437 words (1753915/s), 629950 word types, 1298527 tags\n","2020-07-18 08:45:45,046 : INFO : PROGRESS: at example #1300000, processed 11048564 words (1748801/s), 633332 word types, 1300000 tags\n","2020-07-18 08:45:45,092 : INFO : PROGRESS: at example #1310000, processed 11127767 words (1771148/s), 636666 word types, 1310000 tags\n","2020-07-18 08:45:45,139 : INFO : PROGRESS: at example #1320000, processed 11206572 words (1730553/s), 639949 word types, 1320000 tags\n","2020-07-18 08:45:45,186 : INFO : PROGRESS: at example #1330000, processed 11286055 words (1726443/s), 643323 word types, 1330000 tags\n","2020-07-18 08:45:45,242 : INFO : PROGRESS: at example #1340000, processed 11365174 words (1429035/s), 646580 word types, 1340000 tags\n","2020-07-18 08:45:45,289 : INFO : PROGRESS: at example #1350000, processed 11443380 words (1703063/s), 649786 word types, 1350000 tags\n","2020-07-18 08:45:45,337 : INFO : PROGRESS: at example #1360000, processed 11521605 words (1666980/s), 653078 word types, 1360000 tags\n","2020-07-18 08:45:45,383 : INFO : PROGRESS: at example #1370000, processed 11598778 words (1776499/s), 656204 word types, 1370000 tags\n","2020-07-18 08:45:45,428 : INFO : PROGRESS: at example #1380000, processed 11676242 words (1756872/s), 659329 word types, 1380000 tags\n","2020-07-18 08:45:45,473 : INFO : PROGRESS: at example #1390000, processed 11753449 words (1733846/s), 662433 word types, 1390000 tags\n","2020-07-18 08:45:45,519 : INFO : PROGRESS: at example #1400000, processed 11829366 words (1700315/s), 665535 word types, 1400000 tags\n","2020-07-18 08:45:45,567 : INFO : PROGRESS: at example #1410000, processed 11905886 words (1647196/s), 668533 word types, 1410000 tags\n","2020-07-18 08:45:45,611 : INFO : PROGRESS: at example #1420000, processed 11981218 words (1715156/s), 671569 word types, 1420000 tags\n","2020-07-18 08:45:45,660 : INFO : PROGRESS: at example #1430000, processed 12056300 words (1586888/s), 674570 word types, 1430000 tags\n","2020-07-18 08:45:45,705 : INFO : PROGRESS: at example #1440000, processed 12130122 words (1675169/s), 677425 word types, 1440000 tags\n","2020-07-18 08:45:45,758 : INFO : PROGRESS: at example #1450000, processed 12204074 words (1426663/s), 680239 word types, 1450000 tags\n","2020-07-18 08:45:45,805 : INFO : PROGRESS: at example #1460000, processed 12280246 words (1647650/s), 683043 word types, 1460000 tags\n","2020-07-18 08:45:45,862 : INFO : PROGRESS: at example #1470000, processed 12355868 words (1351141/s), 685887 word types, 1470000 tags\n","2020-07-18 08:45:45,909 : INFO : PROGRESS: at example #1480000, processed 12431969 words (1654790/s), 688774 word types, 1480000 tags\n","2020-07-18 08:45:45,966 : INFO : PROGRESS: at example #1490000, processed 12510698 words (1406892/s), 691795 word types, 1490000 tags\n","2020-07-18 08:45:46,016 : INFO : PROGRESS: at example #1500000, processed 12589321 words (1623434/s), 694816 word types, 1500000 tags\n","2020-07-18 08:45:46,110 : INFO : PROGRESS: at example #1510000, processed 12680391 words (974973/s), 699879 word types, 1510000 tags\n","2020-07-18 08:45:46,165 : INFO : PROGRESS: at example #1520000, processed 12782000 words (1874987/s), 705803 word types, 1520000 tags\n","2020-07-18 08:45:46,226 : INFO : PROGRESS: at example #1530000, processed 12887222 words (1732293/s), 712823 word types, 1530000 tags\n","2020-07-18 08:45:46,282 : INFO : PROGRESS: at example #1540000, processed 12991079 words (1909232/s), 719590 word types, 1540000 tags\n","2020-07-18 08:45:46,335 : INFO : PROGRESS: at example #1550000, processed 13089559 words (1890109/s), 725492 word types, 1550000 tags\n","2020-07-18 08:45:46,389 : INFO : PROGRESS: at example #1560000, processed 13186631 words (1809773/s), 731382 word types, 1560000 tags\n","2020-07-18 08:45:46,443 : INFO : PROGRESS: at example #1570000, processed 13285200 words (1876332/s), 737154 word types, 1570000 tags\n","2020-07-18 08:45:46,495 : INFO : PROGRESS: at example #1580000, processed 13377977 words (1807621/s), 742349 word types, 1580000 tags\n","2020-07-18 08:45:46,549 : INFO : PROGRESS: at example #1590000, processed 13466010 words (1656245/s), 747342 word types, 1590000 tags\n","2020-07-18 08:45:46,616 : INFO : PROGRESS: at example #1600000, processed 13553123 words (1332711/s), 751904 word types, 1600000 tags\n","2020-07-18 08:45:46,672 : INFO : PROGRESS: at example #1610000, processed 13640922 words (1602845/s), 756490 word types, 1610000 tags\n","2020-07-18 08:45:46,728 : INFO : PROGRESS: at example #1620000, processed 13728831 words (1603817/s), 760878 word types, 1620000 tags\n","2020-07-18 08:45:46,781 : INFO : PROGRESS: at example #1630000, processed 13814731 words (1639438/s), 765007 word types, 1630000 tags\n","2020-07-18 08:45:46,834 : INFO : PROGRESS: at example #1640000, processed 13899500 words (1636423/s), 768959 word types, 1640000 tags\n","2020-07-18 08:45:46,887 : INFO : PROGRESS: at example #1650000, processed 13984517 words (1624349/s), 772938 word types, 1650000 tags\n","2020-07-18 08:45:46,934 : INFO : PROGRESS: at example #1660000, processed 14068343 words (1816432/s), 776790 word types, 1660000 tags\n","2020-07-18 08:45:46,981 : INFO : PROGRESS: at example #1670000, processed 14152649 words (1804857/s), 780728 word types, 1670000 tags\n","2020-07-18 08:45:47,033 : INFO : PROGRESS: at example #1680000, processed 14236467 words (1661889/s), 784747 word types, 1680000 tags\n","2020-07-18 08:45:47,082 : INFO : PROGRESS: at example #1690000, processed 14318154 words (1669296/s), 788555 word types, 1690000 tags\n","2020-07-18 08:45:47,130 : INFO : collected 792188 word types and 1699863 unique tags from a corpus of 1699863 examples and 14398187 words\n","2020-07-18 08:45:47,131 : INFO : Updating model with new vocabulary\n","2020-07-18 08:45:47,852 : INFO : New added 230069 unique words (22% of original 1022257) and increased the count of 230069 pre-existing words (22% of original 1022257)\n","2020-07-18 08:45:49,657 : INFO : deleting the raw counts dictionary of 792188 items\n","2020-07-18 08:45:49,679 : INFO : sample=0.001 downsamples 36 most-common words\n","2020-07-18 08:45:49,685 : INFO : downsampling leaves estimated 21632374 word corpus (156.3% of prior 13836068)\n","2020-07-18 08:45:50,527 : INFO : estimated required memory for 460138 words and 500 dimensions: 5470347000 bytes\n","2020-07-18 08:45:50,528 : INFO : updating layer weights\n","2020-07-18 08:46:16,181 : WARNING : Effective 'alpha' higher than previous training cycles\n","2020-07-18 08:46:16,182 : INFO : training model with 2 workers on 371102 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n","2020-07-18 08:46:17,301 : INFO : EPOCH 1 - PROGRESS: at 0.53% examples, 56241 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:18,338 : INFO : EPOCH 1 - PROGRESS: at 1.13% examples, 62439 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:19,344 : INFO : EPOCH 1 - PROGRESS: at 1.72% examples, 65122 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:46:20,349 : INFO : EPOCH 1 - PROGRESS: at 2.32% examples, 66563 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:21,376 : INFO : EPOCH 1 - PROGRESS: at 2.99% examples, 68813 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:22,381 : INFO : EPOCH 1 - PROGRESS: at 3.56% examples, 68974 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:23,504 : INFO : EPOCH 1 - PROGRESS: at 4.17% examples, 68909 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:24,574 : INFO : EPOCH 1 - PROGRESS: at 4.81% examples, 70112 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:25,710 : INFO : EPOCH 1 - PROGRESS: at 5.45% examples, 70531 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:26,794 : INFO : EPOCH 1 - PROGRESS: at 6.09% examples, 71191 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:46:27,859 : INFO : EPOCH 1 - PROGRESS: at 6.72% examples, 71946 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:28,930 : INFO : EPOCH 1 - PROGRESS: at 7.35% examples, 72437 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:30,071 : INFO : EPOCH 1 - PROGRESS: at 7.99% examples, 72586 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:31,205 : INFO : EPOCH 1 - PROGRESS: at 8.66% examples, 72870 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:32,313 : INFO : EPOCH 1 - PROGRESS: at 9.33% examples, 73140 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:33,477 : INFO : EPOCH 1 - PROGRESS: at 10.00% examples, 73136 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:46:34,630 : INFO : EPOCH 1 - PROGRESS: at 10.69% examples, 73292 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:35,811 : INFO : EPOCH 1 - PROGRESS: at 11.40% examples, 73415 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:36,982 : INFO : EPOCH 1 - PROGRESS: at 12.11% examples, 73566 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:38,161 : INFO : EPOCH 1 - PROGRESS: at 12.83% examples, 73688 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:39,173 : INFO : EPOCH 1 - PROGRESS: at 13.47% examples, 73907 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:40,313 : INFO : EPOCH 1 - PROGRESS: at 14.11% examples, 73718 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:41,329 : INFO : EPOCH 1 - PROGRESS: at 14.76% examples, 73931 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:46:42,383 : INFO : EPOCH 1 - PROGRESS: at 15.31% examples, 73397 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:43,489 : INFO : EPOCH 1 - PROGRESS: at 15.95% examples, 73106 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:44,541 : INFO : EPOCH 1 - PROGRESS: at 16.60% examples, 72977 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:46:45,547 : INFO : EPOCH 1 - PROGRESS: at 17.23% examples, 72936 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:46,554 : INFO : EPOCH 1 - PROGRESS: at 17.84% examples, 72894 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:47,757 : INFO : EPOCH 1 - PROGRESS: at 18.59% examples, 72920 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:46:48,848 : INFO : EPOCH 1 - PROGRESS: at 19.24% examples, 73109 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:49,960 : INFO : EPOCH 1 - PROGRESS: at 19.89% examples, 73241 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:51,035 : INFO : EPOCH 1 - PROGRESS: at 20.53% examples, 73409 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:52,195 : INFO : EPOCH 1 - PROGRESS: at 21.17% examples, 73384 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:53,356 : INFO : EPOCH 1 - PROGRESS: at 21.81% examples, 73364 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:54,441 : INFO : EPOCH 1 - PROGRESS: at 22.46% examples, 73518 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:55,539 : INFO : EPOCH 1 - PROGRESS: at 23.11% examples, 73680 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:46:56,626 : INFO : EPOCH 1 - PROGRESS: at 23.77% examples, 73839 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:57,670 : INFO : EPOCH 1 - PROGRESS: at 24.36% examples, 73840 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:46:58,766 : INFO : EPOCH 1 - PROGRESS: at 24.96% examples, 73758 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:46:59,994 : INFO : EPOCH 1 - PROGRESS: at 25.49% examples, 73257 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:01,201 : INFO : EPOCH 1 - PROGRESS: at 26.03% examples, 72814 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:02,212 : INFO : EPOCH 1 - PROGRESS: at 26.50% examples, 72510 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:03,364 : INFO : EPOCH 1 - PROGRESS: at 26.96% examples, 72000 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:04,455 : INFO : EPOCH 1 - PROGRESS: at 27.43% examples, 71610 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:05,605 : INFO : EPOCH 1 - PROGRESS: at 27.91% examples, 71155 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:06,702 : INFO : EPOCH 1 - PROGRESS: at 28.30% examples, 70614 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:07,707 : INFO : EPOCH 1 - PROGRESS: at 28.77% examples, 70396 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:08,749 : INFO : EPOCH 1 - PROGRESS: at 29.11% examples, 69826 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:09,755 : INFO : EPOCH 1 - PROGRESS: at 29.60% examples, 69648 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:10,996 : INFO : EPOCH 1 - PROGRESS: at 30.07% examples, 69171 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:12,020 : INFO : EPOCH 1 - PROGRESS: at 30.46% examples, 68826 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:13,274 : INFO : EPOCH 1 - PROGRESS: at 31.00% examples, 68516 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:14,333 : INFO : EPOCH 1 - PROGRESS: at 31.48% examples, 68311 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:15,352 : INFO : EPOCH 1 - PROGRESS: at 31.88% examples, 68006 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:16,483 : INFO : EPOCH 1 - PROGRESS: at 32.36% examples, 67728 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:17,601 : INFO : EPOCH 1 - PROGRESS: at 32.83% examples, 67472 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:18,685 : INFO : EPOCH 1 - PROGRESS: at 33.31% examples, 67262 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:19,795 : INFO : EPOCH 1 - PROGRESS: at 33.79% examples, 67036 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:20,895 : INFO : EPOCH 1 - PROGRESS: at 34.20% examples, 66690 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:22,000 : INFO : EPOCH 1 - PROGRESS: at 34.62% examples, 66366 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:23,139 : INFO : EPOCH 1 - PROGRESS: at 35.10% examples, 66144 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:24,310 : INFO : EPOCH 1 - PROGRESS: at 35.59% examples, 65906 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:25,495 : INFO : EPOCH 1 - PROGRESS: at 36.10% examples, 65662 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:26,660 : INFO : EPOCH 1 - PROGRESS: at 36.54% examples, 65328 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:27,705 : INFO : EPOCH 1 - PROGRESS: at 36.98% examples, 65111 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:28,719 : INFO : EPOCH 1 - PROGRESS: at 37.41% examples, 64934 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:29,897 : INFO : EPOCH 1 - PROGRESS: at 37.92% examples, 64734 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:31,041 : INFO : EPOCH 1 - PROGRESS: at 38.44% examples, 64575 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:32,081 : INFO : EPOCH 1 - PROGRESS: at 38.89% examples, 64389 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:33,102 : INFO : EPOCH 1 - PROGRESS: at 39.31% examples, 64219 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:34,105 : INFO : EPOCH 1 - PROGRESS: at 39.74% examples, 64068 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:35,163 : INFO : EPOCH 1 - PROGRESS: at 40.10% examples, 63766 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:36,206 : INFO : EPOCH 1 - PROGRESS: at 40.52% examples, 63595 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:37,276 : INFO : EPOCH 1 - PROGRESS: at 40.94% examples, 63399 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:38,290 : INFO : EPOCH 1 - PROGRESS: at 41.35% examples, 63258 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:47:39,314 : INFO : EPOCH 1 - PROGRESS: at 41.76% examples, 63110 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:40,453 : INFO : EPOCH 1 - PROGRESS: at 42.24% examples, 62975 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:41,479 : INFO : EPOCH 1 - PROGRESS: at 42.62% examples, 62816 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:42,556 : INFO : EPOCH 1 - PROGRESS: at 43.08% examples, 62726 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:43,557 : INFO : EPOCH 1 - PROGRESS: at 43.49% examples, 62607 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:44,756 : INFO : EPOCH 1 - PROGRESS: at 43.97% examples, 62445 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:45,769 : INFO : EPOCH 1 - PROGRESS: at 44.43% examples, 62414 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:46,825 : INFO : EPOCH 1 - PROGRESS: at 44.96% examples, 62452 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:47,896 : INFO : EPOCH 1 - PROGRESS: at 45.56% examples, 62571 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:49,071 : INFO : EPOCH 1 - PROGRESS: at 46.23% examples, 62715 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:50,190 : INFO : EPOCH 1 - PROGRESS: at 46.89% examples, 62880 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:51,286 : INFO : EPOCH 1 - PROGRESS: at 47.53% examples, 63052 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:52,470 : INFO : EPOCH 1 - PROGRESS: at 48.18% examples, 63168 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:53,574 : INFO : EPOCH 1 - PROGRESS: at 48.84% examples, 63338 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:54,656 : INFO : EPOCH 1 - PROGRESS: at 49.47% examples, 63508 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:55,782 : INFO : EPOCH 1 - PROGRESS: at 50.09% examples, 63632 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:56,872 : INFO : EPOCH 1 - PROGRESS: at 50.72% examples, 63771 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:57,967 : INFO : EPOCH 1 - PROGRESS: at 51.36% examples, 63907 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:47:59,111 : INFO : EPOCH 1 - PROGRESS: at 52.02% examples, 64019 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:00,239 : INFO : EPOCH 1 - PROGRESS: at 52.68% examples, 64135 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:01,407 : INFO : EPOCH 1 - PROGRESS: at 53.39% examples, 64261 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:02,601 : INFO : EPOCH 1 - PROGRESS: at 54.09% examples, 64375 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:03,628 : INFO : EPOCH 1 - PROGRESS: at 54.65% examples, 64419 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:04,806 : INFO : EPOCH 1 - PROGRESS: at 55.36% examples, 64539 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:05,881 : INFO : EPOCH 1 - PROGRESS: at 55.94% examples, 64559 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:06,885 : INFO : EPOCH 1 - PROGRESS: at 56.59% examples, 64705 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:07,902 : INFO : EPOCH 1 - PROGRESS: at 57.11% examples, 64681 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:08,944 : INFO : EPOCH 1 - PROGRESS: at 57.71% examples, 64722 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:09,964 : INFO : EPOCH 1 - PROGRESS: at 58.30% examples, 64775 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:11,148 : INFO : EPOCH 1 - PROGRESS: at 58.90% examples, 64734 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:12,206 : INFO : EPOCH 1 - PROGRESS: at 59.58% examples, 64843 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:13,243 : INFO : EPOCH 1 - PROGRESS: at 60.11% examples, 64806 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:14,285 : INFO : EPOCH 1 - PROGRESS: at 60.72% examples, 64846 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:15,287 : INFO : EPOCH 1 - PROGRESS: at 61.33% examples, 64908 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:16,305 : INFO : EPOCH 1 - PROGRESS: at 61.95% examples, 64950 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:17,345 : INFO : EPOCH 1 - PROGRESS: at 62.58% examples, 64993 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:18,403 : INFO : EPOCH 1 - PROGRESS: at 63.20% examples, 65027 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:19,420 : INFO : EPOCH 1 - PROGRESS: at 63.82% examples, 65085 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:20,534 : INFO : EPOCH 1 - PROGRESS: at 64.44% examples, 65092 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:21,592 : INFO : EPOCH 1 - PROGRESS: at 65.08% examples, 65172 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:22,725 : INFO : EPOCH 1 - PROGRESS: at 65.72% examples, 65255 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:23,854 : INFO : EPOCH 1 - PROGRESS: at 66.37% examples, 65340 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:24,933 : INFO : EPOCH 1 - PROGRESS: at 67.00% examples, 65447 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:26,023 : INFO : EPOCH 1 - PROGRESS: at 67.64% examples, 65551 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:27,123 : INFO : EPOCH 1 - PROGRESS: at 68.30% examples, 65653 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:28,245 : INFO : EPOCH 1 - PROGRESS: at 68.95% examples, 65745 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:29,341 : INFO : EPOCH 1 - PROGRESS: at 69.60% examples, 65847 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:30,373 : INFO : EPOCH 1 - PROGRESS: at 70.19% examples, 65916 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:31,439 : INFO : EPOCH 1 - PROGRESS: at 70.77% examples, 65975 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:32,456 : INFO : EPOCH 1 - PROGRESS: at 71.39% examples, 66065 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:33,622 : INFO : EPOCH 1 - PROGRESS: at 72.03% examples, 66096 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:34,747 : INFO : EPOCH 1 - PROGRESS: at 72.61% examples, 66080 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:35,913 : INFO : EPOCH 1 - PROGRESS: at 73.32% examples, 66166 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:36,943 : INFO : EPOCH 1 - PROGRESS: at 73.97% examples, 66245 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:37,948 : INFO : EPOCH 1 - PROGRESS: at 74.55% examples, 66280 words/s, in_qsize 3, out_qsize 0\n","2020-07-18 08:48:39,118 : INFO : EPOCH 1 - PROGRESS: at 75.21% examples, 66304 words/s, in_qsize 4, out_qsize 0\n","2020-07-18 08:48:40,138 : INFO : EPOCH 1 - PROGRESS: at 75.87% examples, 66396 words/s, in_qsize 4, out_qsize 0\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"V8hkYjEktSlf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594973716859,"user_tz":-300,"elapsed":922,"user":{"displayName":"Алексей Витомсков","photoUrl":"","userId":"15033448313856548476"}},"outputId":"bdb9a7c3-da82-4936-d167-ca5b501cabfd"},"source":["#Предполагаемый вектор абзаца для нового документа.\n","print(model_dm.infer_vector(['привет', 'я', 'пришел'], epochs=100)) \n","print(model_dbow.infer_vector(['привет', 'я', 'пришел']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 0.5320657   0.6147641  -0.7302554   0.67606187 -0.28112066]\n","[ 0.12734386  0.637806   -0.4460211   0.38215426 -0.45235017]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sEPM8Ulu_rel","colab_type":"text"},"source":["Параметры модели doc2vec\n","\n","документы (итерируемый из списка TaggedDocument, необязательный) - входной корпус может быть просто списком элементов, но для больших корпораций рассмотрим итеративный, который передает документы непосредственно с диска / сети. Если вы не предоставите документы (или файл corpus_file ), модель останется неинициализированной - используйте, если вы планируете инициализировать ее каким-либо другим способом.\n","\n","corpus_file ( str , необязательно ) - путь к файлу корпуса в LineSentenceформате. Вы можете использовать этот аргумент вместо документов, чтобы повысить производительность. Необходимо передать только один из документов или аргументы corpus_file (или ни один из них, в этом случае модель не остается инициализированной). Теги документов назначаются автоматически и равны номеру строки, как в TaggedLineDocument.\n","\n","dm ( {1 , 0} , необязательно ) - определяет алгоритм обучения. Если dm = 1 , используется «распределенная память» (PV-DM). В противном случае используется распределенный пакет слов (PV-DBOW).\n","\n","vector_size ( int , необязательный ) - размерность векторов объектов.\n","\n","window ( int , необязательный ) - максимальное расстояние между текущим и прогнозируемым словом в предложении.\n","\n","альфа (с плавающей точкой , необязательно ) - начальная скорость обучения.\n","\n","min_alpha ( float , необязательно ) - скорость обучения будет линейно снижаться до min_alpha в процессе обучения.\n","\n","seed ( int , необязательный ) - Seed для генератора случайных чисел. Начальные векторы для каждого слова засеяны хешем конкатенации слова + str (семя) . Обратите внимание, что для полностью детерминированно-воспроизводимого прогона вы также должны ограничить модель одним рабочим потоком (worker = 1 ), чтобы исключить дрожание порядка в планировании потоков ОС. В Python 3 воспроизводимость между запусками интерпретатора также требует использования переменной среды PYTHONHASHSEED для управления рандомизацией хеша.\n","\n","min_count ( int , необязательный ) - игнорирует все слова с общей частотой ниже этой.\n","\n","max_vocab_size ( int , необязательный ) - ограничивает ОЗУ при построении словарного запаса; если есть больше уникальных слов, чем это, то удалите редкие слова. Каждые 10 миллионов типов слов требуют около 1 ГБ оперативной памяти. Установите Нет для отсутствия ограничений.\n","\n","sample ( float , необязательный ) - порог для настройки того, какие высокочастотные слова случайным образом отбираются, полезный диапазон (0, 1e-5).\n","\n","working ( int , необязательный ) - используйте эти многочисленные рабочие потоки для обучения модели (= более быстрое обучение на многоядерных машинах).\n","\n","epochs ( int , необязательный ) - количество итераций (эпох) по всему корпусу.\n","\n","hs ( {1 , 0} , необязательно ) - если 1, для обучения модели будет использоваться иерархический softmax. Если установлено значение 0, а отрицательное значение не равно нулю, будет использоваться отрицательная выборка.\n","\n","отрицательный ( int , необязательный ) - если> 0, будет использоваться отрицательная выборка, int для отрицательного указывает, сколько «шумовых слов» следует нарисовать (обычно между 5-20). Если установлено значение 0, отрицательная выборка не используется.\n","\n","ns_exponent ( float , необязательный ) - показатель степени, используемый для формирования отрицательного распределения выборки. Значение 1,0 выборки точно пропорционально частотам, 0,0 выборки всех слов одинаково, в то время как отрицательное значение выборки низкочастотных слов больше, чем высокочастотных слов. Популярное значение по умолчанию 0,75 было выбрано оригинальной статьей Word2Vec. Совсем недавно, в https://arxiv.org/abs/1804.04212 , Caselles-Dupré, Lesaint и Royo-Letelier предлагают, чтобы другие значения могли работать лучше для рекомендательных приложений.\n","\n","dm_mean ( {1 , 0} , необязательно ) - если 0, используйте сумму векторов слова контекста. Если 1, используйте среднее. Применяется только когда dm используется в неконкатентивном режиме.\n","\n","dm_concat ( {1 , 0} , необязательно ) - если 1, использовать конкатенацию векторов контекста, а не сумму / среднее; Обратите внимание, что конкатенация приводит к гораздо большей модели, так как вход больше не является размером одного (сэмплированного или арифметически сложенного) слова-вектора, а размером тега (-ов) и всех слов в контексте, связанных вместе.\n","\n","dm_tag_count ( int , необязательный ) - ожидаемое постоянное количество тегов документа на документ при использовании режима dm_concat.\n","\n","dbow_words ( {1 , 0} , необязательно ) - если установлено значение 1, обучает векторы слов (в режиме пропуска граммы) одновременно с обучением doc-vector DBOW; Если 0, обучаются только векторы документов (быстрее).\n","\n","trim_rule ( функция , необязательно ) -\n","\n","Правило обрезки словаря, указывает, должны ли определенные слова оставаться в словаре, обрезаться или обрабатываться по умолчанию (отбрасывать, если количество слов <min_count). Может быть None (будет использоваться min_count, смотрите keep_vocab_item()) или вызываться, который принимает параметры (word, count, min_count) и возвращает либо gensim.utils.RULE_DISCARD, gensim.utils.RULE_KEEPлибо gensim.utils.RULE_DEFAULT. Правило, если оно задано, используется только для сокращения словарного запаса во время текущего вызова метода и не сохраняется как часть модели.\n","\n","Входные параметры имеют следующие типы:\n","слово (str) - слово, которое мы изучаем\n","\n","count (int) - частота слова в корпусе\n","\n","min_count (int) - минимальный порог счета.\n","\n","обратные вызовы - список обратных вызовов, которые необходимо выполнить / запустить на определенных этапах во время обучения."]}]}